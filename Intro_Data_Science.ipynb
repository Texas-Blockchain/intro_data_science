{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI... ML... Data Science... oOOooO Scary\n",
    "<br>\n",
    "\n",
    "# <><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "\n",
    "<br>\n",
    "\n",
    "# \"Why is Bitcoin going up/down?\"\n",
    "## Trading volume? Google Searches? Tether issuance?\n",
    "\n",
    "## Let's find out!\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# 1) Import packages\n",
    "\n",
    "## *pandas* : your data science go-to\n",
    "*build datasets incredibly easily*\n",
    "\n",
    "## *matplotlib* : for charts\n",
    "*visualize your dat\n",
    "\n",
    "## *sklearn* : for machine learning\n",
    "*train and test statistical models*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Other stuff\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 2) Clean data\n",
    "\n",
    "## Tweak your data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c3bfdd565543>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get .csv file as dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'btc_daily.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Add next-day price column to simulate prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Get .csv file as dataframe\n",
    "data = pd.read_csv('btc_daily.csv')\n",
    "print(data)\n",
    "\n",
    "# Add next-day price column to simulate prediction\n",
    "closes = list(data['close'])\n",
    "closes.insert(0, np.nan)\n",
    "closes.pop()\n",
    "data['next_close'] = closes\n",
    "\n",
    "# Only include full rows\n",
    "data = data.iloc[1:1750]\n",
    "\n",
    "# Expand Google Trends column from weekly to daily by repeating values x7\n",
    "trends = list(data['google_trends'])\n",
    "data['google_trends'] = list(itertools.chain.from_iterable(itertools.repeat(x, 7) for x in trends))[:1749]\n",
    "    \n",
    "# Replace NaN with previous value in column to normalize\n",
    "sp = list(data['sp500'])\n",
    "\n",
    "for index, price in enumerate(sp):\n",
    "    if np.isnan(price):\n",
    "        sp[index] = sp[index-1]\n",
    "\n",
    "data['sp500'] = sp\n",
    "\n",
    "# Show data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 3) Build model\n",
    "\n",
    "## Quantify the relationship between variables\n",
    "\n",
    "* X / Input / Independent / Predictor variables\n",
    "    * Trading volume\n",
    "    * Tether issuance\n",
    "    * Google Trends\n",
    "\n",
    "\n",
    "* Y / Output / Dependent / Response variable\n",
    "    * Bitcoin price\n",
    "\n",
    "<br>    \n",
    "\n",
    "## 3a) Create datasets for variables\n",
    "\n",
    "* X predictor matrix and Y response vector\n",
    "* Split datasets into *train* and *test* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.50630200e+04 3.02000000e+09 6.00000000e+00 2.97762012e+03]\n",
      " [2.31619900e+04 3.02000000e+09 6.00000000e+00 2.98487012e+03]\n",
      " [3.16930900e+04 3.02000000e+09 6.00000000e+00 2.96660010e+03]\n",
      " ...\n",
      " [5.46600000e-01 1.00000000e+02 2.00000000e+00 1.68155005e+03]\n",
      " [1.50100000e+01 1.00000000e+02 2.00000000e+00 1.68155005e+03]\n",
      " [5.65600000e-02 1.00000000e+02 2.00000000e+00 1.68155005e+03]]\n",
      "\n",
      "[8289.0, 8060.0, 8438.35, 8530.01, 9693.74, 10026.8, 9973.99, 10168.85, 10275.01, 10155.26, 10185.39, 10262.54, 10304.46, 10360.25, 10365.93, 10423.72, 10160.2, 10093.01, 10310.0, 10398.97, 10484.37, 10308.92, 10574.73, 10581.84, 10628.48, 10381.26, 9766.52, 9600.86, 9582.42, 9495.0, 9714.31, 10171.85, 10361.65, 10138.72, 10147.96, 10410.85, 10107.15, 10130.0, 10769.09, 10920.0, 10315.48, 10217.79, 10352.78, 10300.01, 10025.86, 10854.92, 11389.28, 11540.76, 11280.95, 11856.1, 11981.0, 11975.03, 11465.49, 11819.49, 10977.51, 10820.76, 10533.01, 10405.94, 10087.3, 9589.01, 9495.01, 9533.0, 9479.98, 9843.0, 9883.33, 9772.6, 9840.12, 10323.39, 10590.7, 10761.03, 10538.06, 10649.07, 9696.31, 9422.72, 10854.47, 10185.03, 11370.08, 11802.0, 11349.0, 12097.96, 12571.11, 12293.53, 11474.42, 11237.77, 11004.51, 11136.0, 11976.42, 10829.18, 10577.63, 10761.26, 11865.29, 12360.45, 11159.29, 12927.44, 11755.53, 11032.32, 10833.02, 10666.86, 10236.2, 9531.21, 9277.54, 9078.48, 9333.14, 8975.0, 8860.23, 8697.46, 8239.04, 8176.02, 7918.17, 8015.69, 7634.58, 7930.14, 7998.13, 7805.0, 7789.48, 7670.96, 8107.96, 8736.55, 8558.95, 8554.06, 8279.69, 8662.44, 8715.36, 8772.29, 8731.72, 8063.81, 8001.7, 7881.98, 7626.48, 7951.7, 7999.54, 8200.0, 7262.4, 7363.69, 7878.96, 8203.32, 7990.92, 7824.93, 6979.76, 7219.95, 6343.14, 6153.09, 5948.41, 5907.47, 5687.9, 5715.86, 5770.01, 5657.4, 5390.01, 5321.15, 5270.69, 5148.25, 5155.0, 5170.6, 5159.51, 5134.81, 5441.9, 5532.75, 5387.6, 5297.64, 5319.89, 5290.37, 5281.81, 5227.0, 5202.9, 5029.99, 5164.27, 5066.22, 5078.19, 5040.12, 5318.58, 5193.49, 5285.54, 5194.79, 5044.13, 5040.66, 4907.3, 4975.97, 4901.93, 4137.01, 3975.01, 3970.5, 3967.01, 3990.0, 3902.8, 3853.95, 3851.02, 3860.0, 3849.68, 3900.92, 3917.0, 3843.12, 3857.05, 3851.89, 3844.59, 3700.72, 3786.93, 3809.7, 3806.17, 3792.14, 3799.92, 3799.48, 3818.79, 3734.22, 4110.0, 3942.02, 3897.71, 3938.99, 3888.01, 3867.0, 3625.08, 3582.37, 3566.59, 3561.5, 3576.68, 3588.06, 3590.36, 3648.85, 3623.73, 3622.0, 3359.0, 3367.36, 3428.4, 3409.57, 3414.78, 3468.43, 3437.5, 3411.49, 3437.55, 3397.42, 3429.95, 3531.01, 3556.07, 3562.18, 3568.97, 3553.01, 3577.03, 3531.76, 3536.19, 3682.65, 3607.85, 3640.65, 3609.71, 3580.76, 3664.19, 3514.24, 3619.41, 3635.69, 3626.12, 4004.12, 3993.86, 4006.01, 4040.99, 3798.62, 3820.25, 3787.57, 3890.79, 3826.09, 3691.86, 3829.0, 3729.31, 3888.06, 3589.89, 3809.88, 3780.0, 4034.0, 3944.93, 3980.46, 3839.06, 4075.34, 3682.51, 3667.77, 3496.82, 3195.0, 3183.0, 3195.71, 3265.0, 3430.24, 3355.68, 3410.15, 3531.18, 3401.0, 3380.01, 3433.26, 3694.39, 3901.84, 3833.47, 4103.19, 4142.01, 3975.48, 4248.0, 4225.03, 3775.0, 3731.32, 3936.69, 3774.99, 4283.8, 4263.66, 4545.11, 4349.23, 4733.5, 5560.0, 5504.17, 5512.24, 5579.52, 5605.46, 6259.35, 6327.86, 6357.6, 6347.42, 6334.89, 6406.25, 6503.12, 6448.5, 6404.0, 6423.28, 6331.96, 6349.8, 6343.99, 6304.18, 6267.63, 6266.0, 6403.62, 6409.12, 6404.87, 6395.58, 6415.97, 6395.14, 6407.65, 6415.88, 6414.0, 6382.98, 6394.96, 6443.7, 6422.16, 6436.98, 6183.49, 6196.0, 6188.01, 6154.69, 6524.56, 6589.48, 6608.07, 6570.0, 6552.43, 6593.94, 6547.45, 6466.03, 6498.46, 6572.83, 6605.0, 6582.0, 6620.01, 6680.01, 6455.66, 6436.89, 6582.09, 6696.99, 6707.33, 6750.0, 6493.11, 6386.94, 6335.7, 6250.7, 6498.0, 6518.68, 6478.04, 6485.99, 6326.0, 6282.53, 6299.99, 6235.01, 6188.0, 6395.01, 6495.0, 6687.96, 7360.0, 7256.98, 7295.0, 7191.08, 7015.01, 6983.0, 7030.9, 7071.01, 6911.9, 6709.98, 6737.52, 6690.88, 6526.36, 6359.99, 6475.9, 6258.74, 6489.53, 6396.64, 6585.49, 6315.9, 6269.01, 6195.01, 6253.67, 6112.21, 6112.21, 6146.01, 6546.46, 6282.5, 6718.22, 6938.0, 7030.01, 7005.0, 7414.08, 7533.92, 7603.99, 7727.27, 8170.01, 8216.34, 8228.9, 8184.21, 7931.99, 8157.15, 8401.01, 7720.09, 7397.8, 7408.0, 7334.46, 7470.01, 7378.99, 7315.01, 6728.81, 6348.73, 6248.65, 6216.29, 6249.75, 6390.04, 6303.7, 6664.01, 6701.97, 6753.28, 6600.0, 6532.95, 6587.47, 6502.62, 6611.79, 6349.5, 6383.19, 6202.36, 5851.66, 6132.17, 6074.94, 6246.01, 6149.99, 6178.29, 6059.82, 6719.01, 6756.1, 6736.41, 6709.02, 6447.16, 6484.29, 6391.22, 6638.49, 6302.32, 6544.99, 6881.0, 6770.31, 7496.4, 7618.8, 7684.93, 7655.0, 7612.51, 7487.37, 7706.37, 7636.42, 7514.32, 7485.0, 7380.01, 7460.0, 7107.94, 7346.64, 7337.95, 7459.11, 7584.15, 7505.0, 7987.7, 8393.44, 8516.86, 8235.6, 8238.51, 8059.0, 8344.0, 8477.46, 8670.0, 8686.1, 8475.0, 8403.33, 9010.51, 9300.08, 9177.81, 9353.0, 9600.0, 9800.0, 9685.0, 9725.74, 9190.48, 9072.29, 9243.83, 9389.01, 9329.99, 8922.55, 9272.11, 8865.98, 9648.0, 8931.3, 8795.01, 8915.42, 8866.27, 8274.0, 8152.05, 7892.1, 8048.93, 8355.25, 8003.11, 7893.19, 7916.0, 6942.99, 6824.99, 6771.13, 7020.01, 6894.01, 6619.01, 6785.85, 6791.68, 7424.9, 7045.01, 6816.01, 6928.5, 6848.01, 7079.99, 7942.72, 7793.61, 8145.0, 8453.0, 8531.34, 8927.1, 8715.09, 8891.81, 8900.0, 8589.01, 8192.0, 7857.6, 8275.0, 8259.99, 8207.02, 9145.41, 9120.0, 9533.88, 8795.44, 9255.0, 9304.89, 9925.0, 10700.0, 11377.54, 11469.9, 11432.5, 11000.0, 10895.92, 10307.27, 10566.57, 10300.0, 9597.99, 9688.62, 10144.99, 9830.0, 10454.27, 11235.57, 11140.0, 10380.04, 11121.5, 10167.49, 10031.23, 9472.98, 8520.01, 8872.28, 8072.99, 8547.49, 8671.01, 8218.1, 7575.75, 7688.46, 6905.19, 8167.9, 9240.0, 8787.52, 9010.61, 10099.99, 9995.0, 11123.01, 11536.0, 11319.0, 11086.89, 11118.0, 11356.79, 10824.94, 10766.7, 11518.16, 12762.8, 11498.99, 11305.53, 11200.01, 11570.01, 13590.0, 13656.23, 14187.95, 13820.0, 13308.06, 14875.18, 14480.99, 14993.74, 16174.22, 17099.0, 16960.01, 15144.99, 15098.14, 14781.51, 13480.01, 13863.13, 12839.99, 14565.05, 14450.01, 15367.08, 15790.88, 14171.98, 14221.94, 15065.51, 14210.57, 15758.8, 16496.9, 17838.73, 19039.0, 19378.99, 19650.0, 17738.67, 16749.79, 16689.61, 17730.12, 16885.75, 15290.01, 15309.98, 16367.03, 17390.01, 14090.0, 11718.35, 11643.98, 11290.0, 10930.23, 10869.84, 9903.0, 9935.98, 9949.0, 9768.71, 9401.11, 8795.5, 8215.01, 8031.16, 8250.0, 8109.0, 8256.01, 8031.82, 7777.01, 7714.71, 7838.53, 7294.0, 6605.0, 6535.87, 5886.35, 6346.7, 6577.63, 7156.0, 7467.96, 7126.63, 6969.76, 7392.0, 7412.55, 7170.01, 7039.99, 6783.69, 6445.01, 6124.16, 6140.01, 5752.01, 5780.0, 5891.61, 5739.97, 5525.43, 5905.99, 6005.05, 6024.86, 5989.1, 5704.01, 5574.44, 5594.0, 5754.9, 5693.7, 5819.13, 5624.8, 5440.0, 4814.99, 4750.0, 4769.55, 4603.49, 4425.0, 4362.99, 4320.04, 4214.84, 4307.99, 4392.71, 4394.81, 4339.0, 4156.99, 4189.42, 4200.0, 3885.09, 3919.78, 3669.01, 3787.33, 3619.01, 3617.47, 3867.05, 3910.11, 4100.0, 3719.97, 3726.51, 3740.02, 3250.4, 3855.32, 4164.52, 4210.72, 4251.36, 4334.36, 4350.0, 4624.18, 4616.18, 4432.51, 4498.25, 4626.05, 4649.99, 4947.99, 4743.94, 4581.98, 4599.0, 4384.99, 4340.11, 4344.32, 4360.0, 4312.03, 4143.49, 4092.0, 4002.0, 4050.99, 4157.41, 4101.72, 4280.01, 4370.01, 4159.93, 4320.6, 4060.47, 3874.0, 3656.15, 3444.98, 3342.8, 3422.43, 3398.23, 3222.22, 3243.49, 2857.34, 2787.02, 2699.9, 2732.59, 2856.88, 2723.99, 2700.21, 2786.07, 2664.99, 2525.99, 2564.0, 2762.26, 2754.28, 2825.27, 2657.45, 2873.48, 2258.99, 2308.15, 2235.19, 1910.86, 1964.31, 2217.24, 2340.0, 2383.42, 2310.01, 2331.05, 2508.99, 2561.11, 2501.15, 2604.84, 2616.96, 2602.0, 2542.41, 2516.66, 2423.63, 2455.19, 2530.0, 2553.25, 2575.75, 2407.91, 2505.61, 2574.84, 2690.76, 2679.99, 2643.35, 2725.08, 2596.98, 2515.25, 2634.94, 2480.43, 2409.98, 2432.21, 2709.01, 2655.71, 2998.98, 2932.44, 2811.39, 2799.73, 2685.64, 2871.29, 2698.0, 2521.36, 2548.05, 2478.99, 2419.99, 2303.29, 2191.58, 2279.48, 2232.78, 2099.99, 2272.7, 2355.0, 2432.97, 2272.75, 2123.29, 2057.0, 2058.91, 1976.23, 1899.16, 1813.23, 1777.48, 1747.81, 1799.99, 1792.73, 1695.61, 1837.93, 1794.99, 1720.43, 1713.0, 1609.57, 1585.39, 1551.3, 1563.39, 1533.0, 1471.99, 1436.5, 1384.55, 1365.43, 1353.34, 1349.26, 1298.44, 1281.16, 1257.29, 1251.98, 1247.0, 1249.99, 1236.15, 1214.21, 1201.94, 1189.91, 1177.99, 1178.85, 1173.74, 1177.05, 1214.17, 1223.99, 1210.0, 1210.97, 1184.5, 1194.0, 1192.3, 1132.99, 1143.99, 1152.6, 1113.99, 1092.0, 1088.99, 1042.08, 1043.27, 1045.4, 1042.08, 973.08, 963.72, 934.87, 1025.14, 1034.57, 1114.42, 1044.96, 1019.49, 970.0, 1069.57, 1175.11, 1263.0, 1247.42, 1245.5, 1235.58, 1188.11, 1109.01, 1197.3, 1150.22, 1237.36, 1284.99, 1278.98, 1273.97, 1292.86, 1269.17, 1230.0, 1195.08, 1195.81, 1184.91, 1158.0, 1186.91, 1186.9, 1128.71, 1128.29, 1089.86, 1059.88, 1062.15, 1057.3, 1038.94, 1014.53, 1012.23, 1002.56, 1010.0, 1018.43, 1003.97, 985.0, 1059.14, 1053.97, 1024.39, 1019.31, 1035.84, 1016.77, 1007.66, 989.71, 970.92, 923.45, 917.31, 924.7, 923.4, 917.93, 896.81, 894.86, 924.24, 924.98, 925.36, 894.05, 901.0, 880.0, 907.58, 831.89, 830.0, 829.62, 830.79, 822.64, 801.5, 907.53, 905.41, 916.6, 903.7, 894.93, 995.05, 1133.0, 1035.19, 1019.01, 996.82, 970.47, 962.63, 976.75, 981.92, 921.59, 901.98, 896.73, 887.0, 915.5, 858.01, 828.58, 797.99, 789.91, 790.0, 790.07, 785.0, 775.0, 777.72, 779.79, 778.71, 770.9, 775.98, 771.77, 768.35, 766.07, 755.73, 753.36, 766.96, 766.52, 771.54, 753.57, 742.6, 731.8, 730.27, 729.01, 735.83, 739.0, 737.99, 741.76, 747.0, 735.81, 731.0, 750.38, 747.8, 736.57, 737.55, 712.41, 705.52, 703.98, 704.67, 714.77, 712.28, 721.0, 712.57, 706.82, 716.83, 706.9, 705.7, 688.93, 735.5, 731.16, 699.68, 697.65, 717.9, 689.65, 685.57, 674.0, 649.07, 649.75, 650.54, 655.0, 629.76, 627.83, 629.68, 634.97, 638.96, 642.53, 637.51, 638.0, 635.86, 636.92, 643.83, 618.31, 617.58, 619.59, 617.32, 611.83, 613.35, 609.25, 612.95, 612.41, 616.0, 607.65, 605.07, 604.98, 605.3, 606.82, 601.35, 603.69, 602.68, 595.25, 596.95, 608.98, 608.94, 610.99, 607.83, 607.75, 607.01, 608.95, 608.24, 607.48, 607.25, 625.1, 622.6, 628.77, 614.59, 612.37, 606.19, 611.82, 600.58, 575.38, 571.96, 571.59, 574.79, 573.0, 574.83, 570.42, 578.89, 576.16, 578.92, 582.58, 585.12, 580.65, 583.21, 574.49, 573.99, 573.83, 581.97, 568.09, 572.43, 586.0, 587.82, 589.22, 593.24, 588.13, 591.91, 593.9, 590.98, 582.98, 585.0, 576.0, 515.38, 603.97, 623.14, 656.32, 657.27, 656.67, 657.04, 657.73, 657.39, 660.27, 658.19, 653.69, 667.73, 667.94, 673.89, 675.4, 679.08, 666.45, 668.28, 661.41, 662.57, 674.02, 651.7, 652.54, 658.78, 666.5, 640.3, 678.0, 668.45, 679.0, 669.0, 701.23, 680.61, 672.45, 639.22, 647.63, 650.31, 639.13, 677.72, 668.6, 630.87, 594.68, 669.99, 730.42, 767.98, 760.08, 753.0, 770.21, 694.83, 684.9, 706.0, 674.26, 595.82, 579.5, 578.56, 583.23, 579.33, 585.99, 574.86, 575.56, 570.0, 538.53, 536.99, 531.47, 533.0, 524.7, 528.04, 470.94, 454.68, 451.78, 446.5, 444.88, 442.54, 446.14, 444.27, 442.41, 455.19, 453.62, 456.78, 462.26, 458.99, 457.49, 455.83, 454.46, 452.92, 464.24, 461.91, 462.2, 462.87, 450.39, 449.06, 452.68, 445.61, 456.51, 453.48, 457.74, 451.3, 446.85, 470.37, 467.41, 463.85, 453.94, 448.29, 452.65, 442.85, 436.87, 429.57, 434.72, 434.72, 430.92, 426.1, 425.53, 428.27, 423.28, 423.48, 419.49, 418.97, 421.58, 421.57, 422.18, 419.31, 420.07, 419.9, 417.33, 416.44, 412.5, 416.5, 422.42, 425.03, 416.7, 416.57, 413.76, 417.3, 416.42, 411.38, 413.58, 410.55, 409.96, 418.5, 415.93, 414.65, 414.01, 413.15, 410.33, 418.81, 416.24, 412.83, 411.23, 415.43, 403.48, 396.79, 408.93, 418.82, 423.69, 432.4, 436.45, 433.69, 432.51, 427.5, 423.75, 422.79, 420.03, 436.9, 438.15, 441.89, 419.06, 421.32, 416.26, 406.89, 399.11, 404.53, 388.37, 381.97, 376.89, 378.56, 372.9, 370.68, 377.77, 374.92, 384.46, 390.08, 367.0, 372.85, 370.62, 369.82, 379.23, 379.39, 379.96, 394.93, 389.21, 392.91, 403.45, 389.52, 383.01, 408.97, 413.88, 375.96, 383.14, 381.01, 386.57, 373.43, 429.69, 432.68, 446.57, 449.33, 449.14, 451.07, 454.06, 458.49, 432.44, 432.67, 433.42, 432.51, 435.74, 435.43, 430.12, 428.2, 432.59, 421.28, 425.01, 419.76, 456.09, 456.0, 443.77, 434.88, 436.61, 442.26, 460.9, 462.5, 455.5, 453.63, 463.64, 441.98, 436.29, 436.01, 451.34, 416.18, 417.44, 409.2, 395.28, 393.26, 387.0, 363.25, 361.33, 360.23, 362.56, 378.23, 371.04, 355.94, 359.99, 356.88, 328.07, 319.49, 323.01, 323.59, 325.22, 321.85, 325.5, 336.59, 336.0, 332.1, 321.13, 333.49, 335.0, 336.19, 307.54, 338.46, 381.0, 373.91, 386.7, 371.37, 384.2, 398.09, 399.49, 363.97, 331.71, 314.6, 329.97, 315.68, 303.75, 295.88, 286.75, 288.97, 284.0, 278.07, 275.92, 269.16, 271.14, 264.81, 264.53, 271.35, 263.0, 254.64, 253.22, 250.37, 246.29, 248.9, 246.06, 244.46, 243.38, 243.64, 246.83, 240.7, 239.76, 239.93, 237.99, 238.54, 237.13, 237.78, 240.42, 233.54, 234.99, 235.76, 235.6, 230.1, 230.61, 227.0, 232.48, 232.26, 233.19, 233.17, 229.2, 230.36, 231.01, 230.61, 236.92, 241.04, 238.33, 238.72, 244.15, 240.31, 240.93, 230.92, 231.61, 226.83, 229.39, 227.6, 231.12, 229.24, 229.55, 233.4, 224.34, 226.35, 223.58, 213.38, 228.3, 230.62, 233.71, 235.49, 227.84, 247.43, 258.49, 259.19, 262.21, 266.52, 264.92, 269.43, 271.2, 265.18, 267.91, 261.08, 279.54, 279.91, 282.24, 285.31, 281.63, 282.55, 282.06, 284.68, 288.25, 289.53, 295.73, 294.44, 293.25, 289.64, 289.48, 276.91, 277.5, 277.13, 278.7, 275.59, 277.56, 279.95, 278.71, 285.22, 288.2, 292.35, 311.96, 294.77, 286.85, 270.21, 270.64, 267.19, 270.41, 271.15, 260.72, 256.36, 255.22, 257.97, 264.94, 257.57, 249.79, 251.67, 243.0, 242.14, 240.89, 244.07, 247.75, 244.64, 246.67, 245.56, 248.93, 248.37, 251.93, 237.47, 233.6, 233.18, 230.26, 229.62, 228.67, 229.74, 229.02, 223.96, 225.02, 225.33, 224.31, 225.57, 225.25, 223.6, 229.88, 232.93, 236.94, 236.8, 237.74, 237.61, 237.47, 240.91, 239.07, 240.34, 235.72, 234.25, 232.4, 233.28, 237.22, 236.73, 237.84, 237.19, 237.56, 242.81, 242.81, 241.25, 242.57, 244.65, 237.91, 230.89, 236.18, 239.8, 240.63, 236.26, 234.01, 236.59, 225.91, 225.48, 227.2, 220.5, 227.06, 232.38, 235.49, 234.0, 234.91, 225.04, 224.05, 223.99, 223.5, 229.09, 223.88, 220.53, 238.03, 238.03, 238.13, 235.86, 243.65, 246.65, 255.67, 257.57, 261.46, 254.87, 255.68, 254.48, 247.25, 245.26, 248.59, 243.58, 253.47, 248.68, 250.16, 247.0, 248.81, 265.61, 270.0, 261.83, 263.71, 263.28, 258.51, 286.87, 292.03, 287.46, 284.29, 287.0, 296.11, 296.63, 292.56, 290.23, 274.82, 276.33, 273.91, 277.12, 273.56, 282.42, 274.93, 258.78, 255.51, 255.96, 237.1, 238.45, 240.13, 239.69, 236.72, 245.86, 245.89, 242.42, 235.91, 244.0, 236.82, 234.0, 257.48, 236.65, 222.45, 220.02, 220.84, 222.19, 224.16, 228.7, 222.82, 216.0, 226.5, 228.31, 237.79, 227.0, 219.0, 232.55, 234.52, 236.14, 262.69, 270.0, 254.53, 240.0, 235.0, 226.32, 225.51, 208.0, 225.51, 184.0, 184.0, 199.46, 211.91, 120.0, 260.0, 288.99, 288.99, 288.99, 288.99, 288.99, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 360.5, 360.5, 375.0, 375.0, 378.0, 378.0, 377.1, 377.1, 378.0, 378.0]\n",
      "\n",
      "(1311, 4)\n",
      "1311\n",
      "\n",
      "(438, 4)\n",
      "438\n"
     ]
    }
   ],
   "source": [
    "# Get input values from dataframe\n",
    "x = data[['vol_btc', 'usdt_supply', 'google_trends', 'sp500']].copy().values\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# Get output values from dataframe\n",
    "y = list(data['next_close'])\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "# Separate train and test data\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=.25)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(len(y_train))\n",
    "print()\n",
    "print(x_test.shape)\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## 3b) Fit model\n",
    "\n",
    "* Use train data to fit a statistical model\n",
    "* Use test data to make predictions\n",
    "* Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6600.47768694   945.50983268  1197.91529601   483.59827533\n",
      "   359.35776413  9836.97407947  8128.35269742   637.0334338\n",
      "   562.07941663  1056.17713555   523.9454527    720.25847697\n",
      "  2672.47507083   409.34820314  6956.68772212   355.06372737\n",
      "  8602.52027725  7060.15039194   524.78347811  7202.5769071\n",
      "  7228.76093796   604.76551997   406.02558583   798.57849987\n",
      "  6592.79744533  7301.57218617   920.20704568  3216.48083651\n",
      "  3027.20799353   770.1274441    631.68614697   489.94337446\n",
      "  7467.46203272  6920.86048614  7293.68145866   904.39104475\n",
      "   620.89376661   727.53337743   472.95974094  6831.61350463\n",
      "  1223.45441885   876.25407504  3664.04752318   630.4313036\n",
      "   619.05328205  7106.19034522   409.90230077   518.61898109\n",
      "  7821.48799722  1187.97612269  6539.66703259  6610.95699918\n",
      "   425.86513578   586.34946866  6857.2756023    387.10127661\n",
      "  7157.66780585  6739.39736756  1283.89728466  6363.68061562\n",
      "   291.80630655   291.33919811   970.11157819   388.38629493\n",
      "  9881.33476999   391.67305876  6782.30519988  6535.22790358\n",
      "   377.23704319   517.49985483  7163.39623274  7826.96038952\n",
      "   776.7143518   7473.84490395  6813.99810951   612.80635999\n",
      "  7338.88255448  2352.13727325  8799.70037219   538.27249794\n",
      "  1250.38236484  5922.23220403  7409.16168247  7099.10464735\n",
      "  6655.08180745  2882.90526779  8375.89698295  6554.60655034\n",
      " 10017.214       6781.28537835   702.2762697   7498.92809674\n",
      "  6298.63344083  9792.18729207  7325.2470828   8656.92347957\n",
      "   372.32847407  6609.81762481  1677.6224629   6924.4514675\n",
      "   884.26829007   400.68247189  6854.57221203   457.06763819\n",
      "   610.40000601  7405.4233183   7562.98180698   435.28269824\n",
      "   645.55915442  1074.70273649  7051.06941277   589.90556857\n",
      " 16359.50802595  3300.90675531  7004.81856144   516.27416415\n",
      "  7311.89217609   881.8716069    481.70016536   389.19208639\n",
      "  8040.82496853  7014.93655541   291.80462779   500.26365548\n",
      "  2404.6343115   8102.10263814   562.5585849    291.80699155\n",
      "   291.33904822  3370.92204954   628.69262673  7689.30730844\n",
      "   369.32122445 12340.63470215   291.33904822   589.62363694\n",
      "  7083.68411779   638.17769705   427.86974413  3751.05774758\n",
      "   434.21621893   569.75686138  6889.02928702   850.28906863\n",
      "   663.00903574   563.67057137  6256.15950337  7391.90531396\n",
      "   472.51426322   636.53534015   633.44027992 12491.56036125\n",
      "   647.60828675  8069.43087584  7118.95482883   556.29238166\n",
      "  2241.9946482    586.97413461   548.12792318   784.29887367\n",
      "  6676.94070517   405.31585866  2678.80483727  7848.50306203\n",
      "   618.9277863    585.07986077  6134.9021917   7209.91286434\n",
      "   586.24245383  7017.25805093   723.02225121  2235.15474034\n",
      "   367.95423146  1833.25599262  2502.77659589   596.9471149\n",
      " 11296.5189189    442.06726061  7447.18686021   581.96944341\n",
      "  7492.74328547   469.63287892  6511.64401654   494.84882003\n",
      "   493.10041957   660.90506342   540.85924671  7108.01624075\n",
      "  1101.22098055  7611.39505812   762.65484741   453.78728003\n",
      "   564.21666428   479.14041797  6470.62941428  3608.24536581\n",
      "  2391.99831858  6797.37232608   605.22379013   510.83035121\n",
      "   641.47425959   616.9173568    717.50499234  6684.14228756\n",
      "  6642.72219382   580.2913119    594.96203842   374.01095315\n",
      "   635.44478251   444.90248138   441.14966135   876.91458857\n",
      "  2570.31152752  7124.58592926   564.89893315   620.48348319\n",
      "  6656.18881408  6932.54979717 15847.44851101  1074.10862988\n",
      "  6312.53599636   652.3602405    366.94878707  3054.26343541\n",
      " 12479.07231377  7335.36122231 10228.21037703   611.52088677\n",
      "   357.62249243   615.09563432  8450.70838626   444.90248138\n",
      "   540.08473127  3058.34640739   424.864458   10392.95968015\n",
      "  2191.66233376  6485.50158213  6274.14553412  7098.15499716\n",
      "   624.55721801   738.99736394   567.06949071   674.99959589\n",
      "  1252.18007551  3674.29831431  7895.24060074  7311.0545613\n",
      "   722.53065945   796.76874414   487.34328024   372.14351033\n",
      "   892.39491783  7468.61818351   787.52372271  6137.99240097\n",
      "   623.37278782   756.27302461   728.17906806  9944.72154534\n",
      "   611.53839985   622.73146407  8474.30273327   769.17556311\n",
      "   684.1695139  16770.982174    5278.36616999   808.30935885\n",
      "  6751.89817937  2661.92867453  2289.96836864  6161.37661039\n",
      "  7317.65343869   387.21445817   607.67452907   530.33614135\n",
      "  3024.00086572   412.51561621   620.81329303  7155.26724217\n",
      "   533.12285794   628.62201164  7720.03661998   847.66595957\n",
      "   664.81485571   291.339348     528.40085187   621.95122376\n",
      "  8098.82382931  6599.70090182   493.47015796  3634.58117041\n",
      "   629.59197773   946.51867324  1030.64844302  2369.54024758\n",
      "   613.64023385  7578.36898063   524.2853055    504.33839587\n",
      "   529.69459597  7429.21056518 10433.73015636  7030.03429506\n",
      "  7280.31853794  8459.80721717   847.06030498  5102.23846825\n",
      "  2525.15787923  7394.67659332   423.37515511   519.15135967\n",
      "  3761.54144623  6960.73104035  3714.62748555  7024.14493824\n",
      "  7081.57765443  7164.07507277   699.02161415   770.69593443\n",
      "  7957.37606752   457.10723918 10514.78113454   673.5699891\n",
      "  7892.95923588  5844.50688545   648.77969914  9359.82203855\n",
      "   401.33733947   473.57179705  6708.12575715  6927.4228125\n",
      "   631.04914189  7048.47258708  7371.31225471  6930.8579035\n",
      "  2544.65707022   815.75272408  7151.5983046    405.28213527\n",
      " 18718.32428235   391.57594524   685.94354909   534.86105309\n",
      " 11848.27353404   495.59675238  6609.32404659  6678.86365705\n",
      "  7389.73364612  6768.27141983   369.031338    8357.08066229\n",
      "   674.45506774  3566.05928971  2619.88699307  2854.74892943\n",
      "   442.3823855    553.5947319    945.60491288   390.80326444\n",
      "  6568.59445558  5703.34458264   823.96030224   544.62455505\n",
      "  9013.19565882  1000.06268212   406.6564111   1331.18561933\n",
      "  7118.47628891  7131.36492902  5365.68113461 12397.03461728\n",
      "   440.9997867    618.85897689   516.47121935  1885.48142263\n",
      "   599.95872491 12493.98866143  9721.24367185  8714.29148253\n",
      " 10417.00335737   476.15929626   565.63883666   466.30233239\n",
      "  7721.18300381  7078.99712367   517.05565073   364.10914518\n",
      "  2614.80575388  6974.63542509   591.00395585 10435.75407711\n",
      "  6963.83607985   435.50916647   444.90248138  7647.77377762\n",
      "   459.76026983  7771.01816359  7481.85564498  6548.1377509\n",
      "   910.61026739   503.3385988   8800.39972002   354.23588721\n",
      "  1015.48806939  2691.18634548   632.75390336  7089.57610868\n",
      "  9506.4805068    370.36835307 10038.38478129   551.33133141\n",
      "  6594.28816893  6152.09516424   792.84886539  6133.3217305\n",
      "   506.06336379  6429.54633476  2450.69970324   402.80131103\n",
      "  9776.01069119   999.67541966 17102.20502802   523.68250765\n",
      "  6780.56031164   602.04824612  3009.95277479   895.53778047\n",
      "  1265.06958766   876.0265304    944.02158318 15999.09522711\n",
      "   436.25402809   959.95591548  6128.45403024   291.34257063\n",
      "   428.25196256   705.64234215]\n",
      "\n",
      "--LINEAR REGRESSION RESULTS--\n",
      "[1.49889582e-02 1.85121100e-06 1.53097854e+02 6.24713481e-01]\n",
      "0.8657666981511859\n",
      "0.8657474707134417\n",
      "2216911.8151577795\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression model\n",
    "model_lin = linear_model.LinearRegression()\n",
    "model_lin.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions based on test inputs\n",
    "pred_lin = model_lin.predict(x_test)\n",
    "print(pred_lin)\n",
    "print()\n",
    "\n",
    "# Score predictions with test outputs and print results\n",
    "print('--LINEAR REGRESSION RESULTS--')\n",
    "print(model_lin.coef_)\n",
    "print(metrics.explained_variance_score(y_test, pred_lin))\n",
    "print(metrics.r2_score(y_test, pred_lin))\n",
    "print(metrics.mean_squared_error(y_test, pred_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## 3c) Optimize\n",
    "\n",
    "* Feature selection\n",
    "    * Check the significance of your inputs\n",
    "    * Consider under/overfitting\n",
    "    \n",
    "* Data transformation\n",
    "    * Normalize your inputs\n",
    "    * Try log() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.926\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.926\n",
      "Method:                 Least Squares   F-statistic:                              5493.\n",
      "Date:                Tue, 01 Oct 2019   Prob (F-statistic):                        0.00\n",
      "Time:                        01:48:16   Log-Likelihood:                         -15227.\n",
      "No. Observations:                1749   AIC:                                  3.046e+04\n",
      "Df Residuals:                    1745   BIC:                                  3.048e+04\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0175      0.004      4.240      0.000       0.009       0.026\n",
      "x2          2.011e-06   3.36e-08     59.800      0.000    1.95e-06    2.08e-06\n",
      "x3           154.1696      3.172     48.604      0.000     147.948     160.391\n",
      "x4             0.0611      0.029      2.112      0.035       0.004       0.118\n",
      "==============================================================================\n",
      "Omnibus:                      165.348   Durbin-Watson:                   0.085\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              997.902\n",
      "Skew:                          -0.191   Prob(JB):                    2.03e-217\n",
      "Kurtosis:                       6.681   Cond. No.                     1.45e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.45e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "                vol_btc  usdt_supply  google_trends     sp500  next_close\n",
      "vol_btc        1.000000     0.239637       0.480154  0.251008    0.436801\n",
      "usdt_supply    0.239637     1.000000       0.271199  0.931924    0.782217\n",
      "google_trends  0.480154     0.271199       1.000000  0.280592    0.693219\n",
      "sp500          0.251008     0.931924       0.280592  1.000000    0.751697\n",
      "next_close     0.436801     0.782217       0.693219  0.751697    1.000000\n",
      "\n",
      "[ 411.91026319 2753.99941578 1616.1902653  2269.54432997]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Linear model summary, check t-values (significance) of inputs\n",
    "lm = sm.OLS(y, x)\n",
    "lm = lm.fit()\n",
    "print(lm.summary())\n",
    "print()\n",
    "\n",
    "# Correlation matrix\n",
    "print(data[['vol_btc', 'usdt_supply', 'google_trends', 'sp500', 'next_close']].copy().corr())\n",
    "print()\n",
    "\n",
    "# Feature selection by f-test\n",
    "f_test = SelectKBest(f_regression, k=2).fit(x, y)\n",
    "print(f_test.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "# 4) Visualize Data\n",
    "\n",
    "## Scatterplots:\n",
    "* Predictions vs. Real Values\n",
    "* Each Input vs. Output\n",
    "* Residuals vs. Predictions (should be uncorrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_lin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eb226743e747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_lin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predictions vs. Real Values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_lin' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "axes.scatter(pred_lin, y_test)\n",
    "plt.title(\"Predictions vs. Real Values\")\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "axes.scatter(y_test, pred_lin - y_test)\n",
    "plt.title(\"Residuals vs. Predictions\")\n",
    "plt.show()\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "ax1.scatter(data['next_close'], data['vol_btc'])\n",
    "ax2.scatter(data['next_close'], data['usdt_supply'])\n",
    "ax3.scatter(data['next_close'], data['google_trends'])\n",
    "ax4.scatter(data['next_close'], data['sp500'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "# 6) Push the limits\n",
    "\n",
    "## Cool... so can we break this thing?\n",
    "\n",
    "* We can try! Let's build a neural network\n",
    "    * Multiple layers of nodes tweak each input slightly\n",
    "    * Can model non-linear relationships\n",
    "    * Resistant to wacky input data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.80622367,  0.34763944,  0.19155755],\n",
      "       [ 0.07119557, -0.16008636,  0.06305531],\n",
      "       [ 0.32137905, -0.35479071,  0.24593453],\n",
      "       [ 0.77202797,  0.6202321 ,  0.51040444]]), array([[ 0.47027324,  0.47118046, -0.76760257,  0.08263214, -0.69977071],\n",
      "       [ 0.11473197,  0.04730881,  0.33885557,  0.46446447, -0.81423612],\n",
      "       [ 0.1384503 ,  0.28375607, -0.1427834 , -0.75927603,  0.10917821]]), array([[-0.34680834],\n",
      "       [ 0.85851568],\n",
      "       [ 0.56986045],\n",
      "       [-0.93175027],\n",
      "       [-0.80776689]])]\n",
      "0.6190508377976627\n",
      "6290612.945236894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Fit model\n",
    "nn = MLPRegressor(activation='identity', solver='lbfgs', hidden_layer_sizes=(3, 5))\n",
    "nn.fit(x_train, y_train)\n",
    "\n",
    "# Predict and score\n",
    "pred_nn = nn.predict(x_test)\n",
    "print(nn.coefs_)\n",
    "print(metrics.r2_score(y_test, pred_nn))\n",
    "print(metrics.mean_squared_error(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
